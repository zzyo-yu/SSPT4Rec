{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 环境设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 设置随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed=2027\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(seed)            # 为CPU设置随机种子\n",
    "torch.cuda.manual_seed(seed)       # 为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed_all(seed)   # 为所有GPU设置随机种子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda ready...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "trm_num = 2              # trm层数\n",
    "trm_head_num = 4         # trm头数\n",
    "trm_hidden_size = 16     # 隐藏层单元数（即历史行为单个token的embed维度）\n",
    "trm_overlay = True       # 使用多个trm叠加（而不是单个循环）\n",
    "maxlen = 20              # 序列最大长度\n",
    "behavior_embed = 16      # 用户行为特征的embedding维度\n",
    "file = 'data/amazon/beauty/beauty_remap_py36.pkl' # 评分文件\n",
    "\n",
    "device = 'cuda'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 工具函数（保存hist）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_history(history, path):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 创建文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = 'hist/' + str(seed) + '/amazon_beauty_pretrain_epochs_log_' + str(seed)\n",
    "histpath = basepath + '/fine'\n",
    "prepath = basepath + '/pre'\n",
    "\n",
    "if not os.path.exists(basepath):   # 如果历史文件夹不存在，先创建\n",
    "    os.mkdir(basepath)\n",
    "    os.mkdir(histpath)\n",
    "    os.mkdir(prepath) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 实验部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Trm4Rec数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from deepctr_torch.process.pretrain_data_precess import create_sequence_amazon_movies_dataset\n",
    "\n",
    "sequence_file = basepath + '/sequence_data.pkl'\n",
    "if os.path.exists(sequence_file):\n",
    "    with open(sequence_file, 'rb') as f:\n",
    "        x, y, feature_columns, behavior_feature_list, item_id_max, pretrain_fea_col = pickle.load(f)\n",
    "else:        \n",
    "    # 生成微调阶段数据\n",
    "    x, y, feature_columns, behavior_feature_list, item_id_max, pretrain_fea_col = create_sequence_amazon_movies_dataset(\n",
    "        file, maxlen, behavior_embed, masked=True, pretrain=True\n",
    "    )\n",
    "    with open(sequence_file, 'wb') as f:\n",
    "        pickle.dump(\n",
    "            (x, y, feature_columns, behavior_feature_list, item_id_max, pretrain_fea_col),\n",
    "            f,\n",
    "            pickle.HIGHEST_PROTOCOL\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 DRIC数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr_torch.process.pretrain_data_precess import create_delete_random_dataset\n",
    "from deepctr_torch.models.trm4rec import Trm4Rec\n",
    "\n",
    "dric_file = basepath + '/dric_data.pkl'\n",
    "\n",
    "prob = [0.1, 0.25]\n",
    "classify=4\n",
    "\n",
    "if os.path.exists(dric_file):\n",
    "    with open(dric_file, 'rb') as f:\n",
    "        dr_sequences, dr_seq_len, dr_labels = pickle.load(f)\n",
    "else:\n",
    "    dr_sequences, dr_seq_len, dr_labels = create_delete_random_dataset(\n",
    "        x['hist_item_id'], x['seq_length'], maxlen, item_id_max, prob, classify=4\n",
    "    )\n",
    "    \n",
    "    with open(dric_file, 'wb') as f:\n",
    "        pickle.dump(\n",
    "            (dr_sequences, dr_seq_len, dr_labels),\n",
    "            f,\n",
    "            pickle.HIGHEST_PROTOCOL\n",
    "        )\n",
    "\n",
    "dr_item_sequence = {\n",
    "    'hist_item_id': dr_sequences,\n",
    "    'seq_length': dr_seq_len\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 创建DRIC模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------创建DRIC------\n"
     ]
    }
   ],
   "source": [
    "from deepctr_torch.models.dric import DRIC\n",
    "from torch.optim import Adam\n",
    "\n",
    "print('------创建DRIC------')\n",
    "\n",
    "dric_model = DRIC(\n",
    "    pretrain_fea_col,\n",
    "    behavior_feature_list,\n",
    "    seq_max_len=maxlen,\n",
    "    device=device,\n",
    "    classify=4,\n",
    "    trm_num=2,\n",
    "    trm_head_num=4,\n",
    "    trm_overlay=True,\n",
    "    trm_hidden_size=behavior_embed,\n",
    ")\n",
    "\n",
    "dric_model.compile(\n",
    "    Adam(dric_model.parameters(), lr=0.002),\n",
    "    'crossentropy',\n",
    "    metrics=['crossentropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 预训练50轮\n",
    "每10轮保存一次权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Train on 783886 samples, validate on 195972 samples, 383 steps per epoch\n",
      "Epoch 1/10\n",
      "33s - loss:  0.0314\n",
      "Epoch 2/10\n",
      "35s - loss:  0.0289\n",
      "Epoch 3/10\n",
      "48s - loss:  0.0277\n",
      "Epoch 4/10\n",
      "56s - loss:  0.0272\n",
      "Epoch 5/10\n",
      "57s - loss:  0.0266\n",
      "Epoch 6/10\n",
      "57s - loss:  0.0258\n",
      "Epoch 7/10\n",
      "56s - loss:  0.0253\n",
      "Epoch 8/10\n",
      "59s - loss:  0.0249\n",
      "Epoch 9/10\n",
      "57s - loss:  0.0244\n",
      "Epoch 10/10\n",
      "57s - loss:  0.0241\n"
     ]
    }
   ],
   "source": [
    "dric_hist= dric_model.fit(\n",
    "    dr_item_sequence,\n",
    "    dr_labels,\n",
    "    batch_size=2048,\n",
    "    epochs=10,\n",
    "    verbose=2,\n",
    "    validation_split=0.2,\n",
    "    save_weight=2,\n",
    "    save_path=prepath + '/dric_weight_epoch_'\n",
    ")\n",
    "\n",
    "save_history(dric_hist, prepath + '/dric_hist.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------创建Trm4Rec------\n",
      "------加载权重------\n",
      "cuda:0\n",
      "Train on 1300478 samples, validate on 325120 samples, 635 steps per epoch\n",
      "Epoch 1/5\n",
      "129s - loss:  0.4914 - auc:  0.8413 - binary_crossentropy:  0.4914 - val_auc:  0.8543 - val_binary_crossentropy:  0.4681\n",
      "Epoch 2/5\n",
      "126s - loss:  0.4044 - auc:  0.8976 - binary_crossentropy:  0.4044 - val_auc:  0.8451 - val_binary_crossentropy:  0.4903\n",
      "Epoch 3/5\n",
      "127s - loss:  0.3105 - auc:  0.9390 - binary_crossentropy:  0.3105 - val_auc:  0.8294 - val_binary_crossentropy:  0.6049\n",
      "Epoch 4/5\n",
      "127s - loss:  0.1989 - auc:  0.9745 - binary_crossentropy:  0.1989 - val_auc:  0.7994 - val_binary_crossentropy:  0.8556\n",
      "Epoch 5/5\n",
      "145s - loss:  0.1104 - auc:  0.9923 - binary_crossentropy:  0.1104 - val_auc:  0.7826 - val_binary_crossentropy:  1.2051\n",
      "------创建Trm4Rec------\n",
      "------加载权重------\n",
      "cuda:0\n",
      "Train on 1300478 samples, validate on 325120 samples, 635 steps per epoch\n",
      "Epoch 1/5\n",
      "128s - loss:  0.4892 - auc:  0.8426 - binary_crossentropy:  0.4892 - val_auc:  0.8564 - val_binary_crossentropy:  0.4653\n",
      "Epoch 2/5\n",
      "132s - loss:  0.3978 - auc:  0.9013 - binary_crossentropy:  0.3978 - val_auc:  0.8457 - val_binary_crossentropy:  0.4925\n",
      "Epoch 3/5\n",
      "136s - loss:  0.3041 - auc:  0.9413 - binary_crossentropy:  0.3041 - val_auc:  0.8286 - val_binary_crossentropy:  0.5977\n",
      "Epoch 4/5\n",
      "126s - loss:  0.1959 - auc:  0.9752 - binary_crossentropy:  0.1959 - val_auc:  0.7995 - val_binary_crossentropy:  0.8391\n",
      "Epoch 5/5\n",
      "138s - loss:  0.1047 - auc:  0.9931 - binary_crossentropy:  0.1047 - val_auc:  0.7745 - val_binary_crossentropy:  1.2147\n",
      "------创建Trm4Rec------\n",
      "------加载权重------\n",
      "cuda:0\n",
      "Train on 1300478 samples, validate on 325120 samples, 635 steps per epoch\n",
      "Epoch 1/5\n",
      "132s - loss:  0.4902 - auc:  0.8421 - binary_crossentropy:  0.4902 - val_auc:  0.8549 - val_binary_crossentropy:  0.4670\n",
      "Epoch 2/5\n",
      "136s - loss:  0.4032 - auc:  0.8981 - binary_crossentropy:  0.4032 - val_auc:  0.8448 - val_binary_crossentropy:  0.4952\n",
      "Epoch 3/5\n",
      "137s - loss:  0.3044 - auc:  0.9412 - binary_crossentropy:  0.3044 - val_auc:  0.8256 - val_binary_crossentropy:  0.6196\n",
      "Epoch 4/5\n",
      "134s - loss:  0.1873 - auc:  0.9776 - binary_crossentropy:  0.1873 - val_auc:  0.7983 - val_binary_crossentropy:  0.8664\n",
      "Epoch 5/5\n",
      "133s - loss:  0.0954 - auc:  0.9942 - binary_crossentropy:  0.0954 - val_auc:  0.7703 - val_binary_crossentropy:  1.3068\n",
      "------创建Trm4Rec------\n",
      "------加载权重------\n",
      "cuda:0\n",
      "Train on 1300478 samples, validate on 325120 samples, 635 steps per epoch\n",
      "Epoch 1/5\n",
      "133s - loss:  0.4902 - auc:  0.8422 - binary_crossentropy:  0.4902 - val_auc:  0.8569 - val_binary_crossentropy:  0.4647\n",
      "Epoch 2/5\n",
      "131s - loss:  0.3991 - auc:  0.9004 - binary_crossentropy:  0.3991 - val_auc:  0.8455 - val_binary_crossentropy:  0.4932\n",
      "Epoch 3/5\n",
      "131s - loss:  0.2974 - auc:  0.9438 - binary_crossentropy:  0.2974 - val_auc:  0.8274 - val_binary_crossentropy:  0.6063\n",
      "Epoch 4/5\n",
      "137s - loss:  0.1846 - auc:  0.9778 - binary_crossentropy:  0.1845 - val_auc:  0.7953 - val_binary_crossentropy:  0.8672\n",
      "Epoch 5/5\n",
      "130s - loss:  0.0906 - auc:  0.9947 - binary_crossentropy:  0.0905 - val_auc:  0.7755 - val_binary_crossentropy:  1.3356\n",
      "------创建Trm4Rec------\n",
      "------加载权重------\n",
      "cuda:0\n",
      "Train on 1300478 samples, validate on 325120 samples, 635 steps per epoch\n",
      "Epoch 1/5\n",
      "137s - loss:  0.4910 - auc:  0.8421 - binary_crossentropy:  0.4910 - val_auc:  0.8544 - val_binary_crossentropy:  0.4677\n",
      "Epoch 2/5\n",
      "139s - loss:  0.4024 - auc:  0.8988 - binary_crossentropy:  0.4024 - val_auc:  0.8433 - val_binary_crossentropy:  0.4958\n",
      "Epoch 3/5\n",
      "132s - loss:  0.3149 - auc:  0.9370 - binary_crossentropy:  0.3149 - val_auc:  0.8274 - val_binary_crossentropy:  0.5935\n",
      "Epoch 4/5\n",
      "133s - loss:  0.2119 - auc:  0.9707 - binary_crossentropy:  0.2119 - val_auc:  0.8013 - val_binary_crossentropy:  0.8551\n",
      "Epoch 5/5\n",
      "133s - loss:  0.1121 - auc:  0.9920 - binary_crossentropy:  0.1121 - val_auc:  0.7824 - val_binary_crossentropy:  1.2454\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    from deepctr_torch.models.trm4rec import Trm4Rec\n",
    "    print('------创建Trm4Rec------')\n",
    "\n",
    "    dr_fine_model = Trm4Rec(\n",
    "        feature_columns,\n",
    "        behavior_feature_list,\n",
    "        maxlen,\n",
    "        device=device,\n",
    "        trm_num=2,\n",
    "        trm_head_num=4,\n",
    "        trm_overlay=trm_overlay,\n",
    "        trm_hidden_size=behavior_embed,\n",
    "        att_weight_normalization=True\n",
    "    )\n",
    "\n",
    "    print('------加载权重------')\n",
    "    # 读取预训练得到的权重\n",
    "    dr_pretrain_weight = torch.load(prepath + '/dric_weight_epoch_' + str(i*2) + '.pth')\n",
    "    # 获取微调模型的权重\n",
    "    dr_fine_weight = dr_fine_model.state_dict()\n",
    "    # 只保留重合部分的权重\n",
    "    model_weight = {\n",
    "        k: v\n",
    "        for k, v in dr_pretrain_weight.items()\n",
    "        if k in dr_fine_weight\n",
    "    }\n",
    "\n",
    "    # 更新微调模型的权重字典\n",
    "    dr_fine_weight.update(model_weight)\n",
    "    # 加载权重\n",
    "    dr_fine_model.load_state_dict(dr_fine_weight)\n",
    "\n",
    "    dr_fine_model.compile(\n",
    "        'adam',\n",
    "        'binary_crossentropy',\n",
    "        metrics=['auc', 'binary_crossentropy']\n",
    "    )\n",
    "\n",
    "    dr_fine_history = dr_fine_model.fit(\n",
    "        x, y,\n",
    "        batch_size=2048,\n",
    "        epochs=5,\n",
    "        verbose=2,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    save_history(dr_fine_history, histpath + '/Trm4Rec' + str(i*2) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}